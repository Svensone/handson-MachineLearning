{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Deep Neural Networks\n",
    "\n",
    "1. Vanishing / Exploding Gradients\n",
    "    - Xavier (Glorot) and He Initialiation (custom kernel_init)\n",
    "    - non-saturational activation (leaky-ReLU, Parametric and Random leaky, Elu, Scaled Relu)\n",
    "    - Batch-Normalization (add before/after activ. no standardization needed, fixup Initial 2019 maybe obsolete ?\n",
    "    - Gradient Clipping (clip_norm/-value, for RNN since no BN)\n",
    "    \n",
    "2. Reusing pretrained Layers\n",
    "\n",
    "- \n",
    "3. Faster Optimizers\n",
    "4. Avoiding Overfitting Through Regularization\n",
    "5. Summary and Practical Guidelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vanishing / Exploding Gradients\n",
    "\n",
    "resaon : all take sigmoid activation (since Mother Nature is using it in biol. neurons :D)\n",
    "\n",
    "- graphical explanation - saturation at the tails\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier (Glorot) and He Initializations\n",
    "\n",
    "- initialization and different activation eliminates van./expl. Gradients risk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x21ecebf68c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(300, activation='relu', kernel_initializer=\"he_normal\") # or he_uniform - same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x21ecebf66c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# customize initializer\n",
    "\n",
    "init = keras.initializers.VarianceScaling(scale=2, mode=\"fan_avg\",\n",
    "                                         distribution=\"uniform\")\n",
    "\n",
    "keras.layers.Dense(300, activation='relu', kernel_initializer=init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Saturating Activiation Functions\n",
    "\n",
    "- leaky relu\n",
    "- parametric leaky rectified linear unit\n",
    "- randomized relu\n",
    "- elu\n",
    "- scaled elu\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# leaky Relu\n",
    "\n",
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN with leaky relu and He Normal Initializer\n",
    "\n",
    "# data\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# set up model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "#compile and train\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 9s 163us/sample - loss: 1.3151 - accuracy: 0.5922 - val_loss: 0.9042 - val_accuracy: 0.7200\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.8140 - accuracy: 0.7349 - val_loss: 0.7240 - val_accuracy: 0.7686\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.6911 - accuracy: 0.7767 - val_loss: 0.6408 - val_accuracy: 0.7946\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 8s 153us/sample - loss: 0.6256 - accuracy: 0.7968 - val_loss: 0.5900 - val_accuracy: 0.8116\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 8s 153us/sample - loss: 0.5837 - accuracy: 0.8100 - val_loss: 0.5589 - val_accuracy: 0.8182\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.5552 - accuracy: 0.8166 - val_loss: 0.5340 - val_accuracy: 0.8284\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 7s 136us/sample - loss: 0.5343 - accuracy: 0.8235 - val_loss: 0.5141 - val_accuracy: 0.8310\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.5180 - accuracy: 0.8263 - val_loss: 0.5013 - val_accuracy: 0.8322\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.5050 - accuracy: 0.8307 - val_loss: 0.4904 - val_accuracy: 0.8356\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.4942 - accuracy: 0.8343 - val_loss: 0.4798 - val_accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ELU\n",
    "\n",
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x21ece783608>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU (scaled exponential linear unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6e5eab987839>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0melu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"b-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.758\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.758\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the SELU activation function\n",
    "\n",
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n",
    "\n",
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)\n",
    "\n",
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "\n",
    "- for or after activation - if before, no bias neuron needed\n",
    "- in diagramms often omitted since considered standard\n",
    "- fixup initialization maybe makes BN obsolete ?\n",
    "- no standardScaler needed since scales and shifts mini_batch input\n",
    "- gamma, beta and mu (mean) and sigma (standard deviation)m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 4 variables per BN layer (gamma, beta, mu, and sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheack which parameters of BN are trainable by the Gradient Descent\n",
    "\n",
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 9s 170us/sample - loss: 1.0468 - accuracy: 0.6830 - val_loss: 0.6881 - val_accuracy: 0.7962\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 8s 146us/sample - loss: 0.6847 - accuracy: 0.7853 - val_loss: 0.5656 - val_accuracy: 0.8200\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.5971 - accuracy: 0.8057 - val_loss: 0.5065 - val_accuracy: 0.8388\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.5491 - accuracy: 0.8177 - val_loss: 0.4716 - val_accuracy: 0.8462\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.5123 - accuracy: 0.8270 - val_loss: 0.4482 - val_accuracy: 0.8554\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 9s 156us/sample - loss: 0.4940 - accuracy: 0.8311 - val_loss: 0.4302 - val_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.4733 - accuracy: 0.8381 - val_loss: 0.4170 - val_accuracy: 0.8624\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 8s 146us/sample - loss: 0.4599 - accuracy: 0.8415 - val_loss: 0.4060 - val_accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.4483 - accuracy: 0.8449 - val_loss: 0.3972 - val_accuracy: 0.8676\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.4378 - accuracy: 0.8476 - val_loss: 0.3902 - val_accuracy: 0.8686\n"
     ]
    }
   ],
   "source": [
    "# applying BN before activation (use_bias = False)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 3. Gradient Clipping\n",
    "    \n",
    "    - all optimizer accept clipnorm/ -value\n",
    "    - input vector [0.002, 1000] becomes [0.002, 1] w clipvalue=1\n",
    "    - direction of input vector might change with clipvalue\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr = 1e-3, clipnorm = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch. 10.1 Vanishing / Exploding Gradients \n",
    "    - Xavier Glorot, He, LeChun Initialization\n",
    "    - Non-Saturating Activation (Selu, leaky, etc)\n",
    "    - BN (fixup initialization 2019)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 2. Reusing Pretrained Models\n",
    "\n",
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43986 samples, validate on 4014 samples\n",
      "Epoch 1/20\n",
      "43986/43986 [==============================] - 8s 174us/sample - loss: 0.5902 - accuracy: 0.8133 - val_loss: 0.3782 - val_accuracy: 0.8692\n",
      "Epoch 2/20\n",
      "43986/43986 [==============================] - 7s 154us/sample - loss: 0.3518 - accuracy: 0.8783 - val_loss: 0.3370 - val_accuracy: 0.8839\n",
      "Epoch 3/20\n",
      "43986/43986 [==============================] - 8s 174us/sample - loss: 0.3163 - accuracy: 0.8896 - val_loss: 0.3019 - val_accuracy: 0.8956\n",
      "Epoch 4/20\n",
      "43986/43986 [==============================] - 7s 162us/sample - loss: 0.2969 - accuracy: 0.8973 - val_loss: 0.2912 - val_accuracy: 0.9013\n",
      "Epoch 5/20\n",
      "43986/43986 [==============================] - 7s 157us/sample - loss: 0.2831 - accuracy: 0.9027 - val_loss: 0.2816 - val_accuracy: 0.9016\n",
      "Epoch 6/20\n",
      "43986/43986 [==============================] - 7s 168us/sample - loss: 0.2725 - accuracy: 0.9065 - val_loss: 0.2736 - val_accuracy: 0.9073\n",
      "Epoch 7/20\n",
      "43986/43986 [==============================] - 7s 154us/sample - loss: 0.2644 - accuracy: 0.9094 - val_loss: 0.2649 - val_accuracy: 0.9093\n",
      "Epoch 8/20\n",
      "43986/43986 [==============================] - 7s 161us/sample - loss: 0.2577 - accuracy: 0.9117 - val_loss: 0.2579 - val_accuracy: 0.9131\n",
      "Epoch 9/20\n",
      "43986/43986 [==============================] - 7s 151us/sample - loss: 0.2517 - accuracy: 0.9137 - val_loss: 0.2581 - val_accuracy: 0.9133\n",
      "Epoch 10/20\n",
      "43986/43986 [==============================] - 7s 149us/sample - loss: 0.2466 - accuracy: 0.9152 - val_loss: 0.2521 - val_accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "43986/43986 [==============================] - 7s 170us/sample - loss: 0.2420 - accuracy: 0.9178 - val_loss: 0.2489 - val_accuracy: 0.9160\n",
      "Epoch 12/20\n",
      "43986/43986 [==============================] - 7s 159us/sample - loss: 0.2381 - accuracy: 0.9191 - val_loss: 0.2454 - val_accuracy: 0.9173\n",
      "Epoch 13/20\n",
      "43986/43986 [==============================] - 7s 164us/sample - loss: 0.2348 - accuracy: 0.9197 - val_loss: 0.2448 - val_accuracy: 0.9193\n",
      "Epoch 14/20\n",
      "43986/43986 [==============================] - 7s 152us/sample - loss: 0.2312 - accuracy: 0.9202 - val_loss: 0.2431 - val_accuracy: 0.9175\n",
      "Epoch 15/20\n",
      "43986/43986 [==============================] - 7s 153us/sample - loss: 0.2282 - accuracy: 0.9220 - val_loss: 0.2430 - val_accuracy: 0.9178\n",
      "Epoch 16/20\n",
      "43986/43986 [==============================] - 7s 150us/sample - loss: 0.2256 - accuracy: 0.9228 - val_loss: 0.2413 - val_accuracy: 0.9155\n",
      "Epoch 17/20\n",
      "43986/43986 [==============================] - 7s 160us/sample - loss: 0.2229 - accuracy: 0.9229 - val_loss: 0.2368 - val_accuracy: 0.9180\n",
      "Epoch 18/20\n",
      "43986/43986 [==============================] - 7s 159us/sample - loss: 0.2202 - accuracy: 0.9243 - val_loss: 0.2433 - val_accuracy: 0.9175\n",
      "Epoch 19/20\n",
      "43986/43986 [==============================] - 6s 147us/sample - loss: 0.2177 - accuracy: 0.9250 - val_loss: 0.2609 - val_accuracy: 0.9053\n",
      "Epoch 20/20\n",
      "43986/43986 [==============================] - 7s 168us/sample - loss: 0.2159 - accuracy: 0.9265 - val_loss: 0.2328 - val_accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "## set up both models A and B (so we have reference values ) afterwards transfer Model A to B\n",
    "\n",
    "# Model A\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 1s 4ms/sample - loss: 0.5480 - accuracy: 0.7400 - val_loss: 0.4336 - val_accuracy: 0.8398\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 0s 527us/sample - loss: 0.3962 - accuracy: 0.8550 - val_loss: 0.3488 - val_accuracy: 0.8905\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 0s 500us/sample - loss: 0.3174 - accuracy: 0.8800 - val_loss: 0.2926 - val_accuracy: 0.9158\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 0s 465us/sample - loss: 0.2610 - accuracy: 0.9250 - val_loss: 0.2527 - val_accuracy: 0.9361\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 0s 466us/sample - loss: 0.2224 - accuracy: 0.9600 - val_loss: 0.2218 - val_accuracy: 0.9544\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.96 - 0s 472us/sample - loss: 0.1909 - accuracy: 0.9700 - val_loss: 0.1973 - val_accuracy: 0.9635\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 0s 491us/sample - loss: 0.1668 - accuracy: 0.9850 - val_loss: 0.1787 - val_accuracy: 0.9696\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 0s 475us/sample - loss: 0.1488 - accuracy: 0.9800 - val_loss: 0.1651 - val_accuracy: 0.9706\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 0s 467us/sample - loss: 0.1338 - accuracy: 0.9850 - val_loss: 0.1528 - val_accuracy: 0.9746\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 0s 454us/sample - loss: 0.1217 - accuracy: 0.9950 - val_loss: 0.1429 - val_accuracy: 0.9767\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 0s 453us/sample - loss: 0.1115 - accuracy: 0.9950 - val_loss: 0.1346 - val_accuracy: 0.9777\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 0s 488us/sample - loss: 0.1028 - accuracy: 0.9950 - val_loss: 0.1273 - val_accuracy: 0.9777\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 0s 480us/sample - loss: 0.0949 - accuracy: 0.9950 - val_loss: 0.1200 - val_accuracy: 0.9797\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 0s 484us/sample - loss: 0.0882 - accuracy: 0.9950 - val_loss: 0.1150 - val_accuracy: 0.9797\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 0s 441us/sample - loss: 0.0823 - accuracy: 0.9950 - val_loss: 0.1100 - val_accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 0s 486us/sample - loss: 0.0773 - accuracy: 0.9950 - val_loss: 0.1058 - val_accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 0s 493us/sample - loss: 0.0729 - accuracy: 0.9950 - val_loss: 0.1013 - val_accuracy: 0.9797\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 0s 470us/sample - loss: 0.0688 - accuracy: 0.9950 - val_loss: 0.0981 - val_accuracy: 0.9797\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 0s 467us/sample - loss: 0.0654 - accuracy: 0.9950 - val_loss: 0.0957 - val_accuracy: 0.9787\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 0s 489us/sample - loss: 0.0622 - accuracy: 0.9950 - val_loss: 0.0927 - val_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "# set up Model B (same parameters as Model A except loss= binary_crossentrophy)\n",
    "\n",
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer model A to B \n",
    "\n",
    "model_A = keras.models.load_model('my_model_A.h5')\n",
    "\n",
    "# all layers except output layer\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "\n",
    "# add output layer for binary classification on model B\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# WATCH OUT ! any time you train Model B_on_A model A will be changed too!\n",
    "\n",
    "# Better clone (but don't forget the set_weights since those not included with clone_model())\n",
    "\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "\n",
    "model_A_clone.set_weights(model_A.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 1s 5ms/sample - loss: 0.1942 - accuracy: 0.9600 - val_loss: 0.2095 - val_accuracy: 0.9726\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 657us/sample - loss: 0.1885 - accuracy: 0.9600 - val_loss: 0.2044 - val_accuracy: 0.9726\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 744us/sample - loss: 0.1834 - accuracy: 0.9600 - val_loss: 0.1995 - val_accuracy: 0.9746\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 673us/sample - loss: 0.1785 - accuracy: 0.9600 - val_loss: 0.1947 - val_accuracy: 0.9767\n",
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/16\n",
      "200/200 [==============================] - 1s 6ms/sample - loss: 0.1655 - accuracy: 0.9650 - val_loss: 0.1695 - val_accuracy: 0.9817\n",
      "Epoch 2/16\n",
      "200/200 [==============================] - 0s 843us/sample - loss: 0.1418 - accuracy: 0.9750 - val_loss: 0.1517 - val_accuracy: 0.9828\n",
      "Epoch 3/16\n",
      "200/200 [==============================] - 0s 787us/sample - loss: 0.1250 - accuracy: 0.9850 - val_loss: 0.1378 - val_accuracy: 0.9838\n",
      "Epoch 4/16\n",
      "200/200 [==============================] - 0s 828us/sample - loss: 0.1119 - accuracy: 0.9850 - val_loss: 0.1264 - val_accuracy: 0.9838\n",
      "Epoch 5/16\n",
      "200/200 [==============================] - 0s 772us/sample - loss: 0.1012 - accuracy: 0.9850 - val_loss: 0.1174 - val_accuracy: 0.9848\n",
      "Epoch 6/16\n",
      "200/200 [==============================] - 0s 776us/sample - loss: 0.0924 - accuracy: 0.9900 - val_loss: 0.1100 - val_accuracy: 0.9878\n",
      "Epoch 7/16\n",
      "200/200 [==============================] - 0s 767us/sample - loss: 0.0854 - accuracy: 0.9950 - val_loss: 0.1034 - val_accuracy: 0.9888\n",
      "Epoch 8/16\n",
      "200/200 [==============================] - 0s 858us/sample - loss: 0.0790 - accuracy: 0.9950 - val_loss: 0.0977 - val_accuracy: 0.9899\n",
      "Epoch 9/16\n",
      "200/200 [==============================] - 0s 794us/sample - loss: 0.0736 - accuracy: 0.9950 - val_loss: 0.0931 - val_accuracy: 0.9899\n",
      "Epoch 10/16\n",
      "200/200 [==============================] - 0s 905us/sample - loss: 0.0692 - accuracy: 0.9950 - val_loss: 0.0885 - val_accuracy: 0.9899\n",
      "Epoch 11/16\n",
      "200/200 [==============================] - 0s 820us/sample - loss: 0.0648 - accuracy: 0.9950 - val_loss: 0.0848 - val_accuracy: 0.9888\n",
      "Epoch 12/16\n",
      "200/200 [==============================] - 0s 832us/sample - loss: 0.0612 - accuracy: 0.9950 - val_loss: 0.0814 - val_accuracy: 0.9888\n",
      "Epoch 13/16\n",
      "200/200 [==============================] - 0s 786us/sample - loss: 0.0580 - accuracy: 0.9950 - val_loss: 0.0784 - val_accuracy: 0.9888\n",
      "Epoch 14/16\n",
      "200/200 [==============================] - 0s 728us/sample - loss: 0.0551 - accuracy: 0.9950 - val_loss: 0.0755 - val_accuracy: 0.9888\n",
      "Epoch 15/16\n",
      "200/200 [==============================] - 0s 884us/sample - loss: 0.0524 - accuracy: 0.9950 - val_loss: 0.0729 - val_accuracy: 0.9888\n",
      "Epoch 16/16\n",
      "200/200 [==============================] - 0s 840us/sample - loss: 0.0498 - accuracy: 0.9950 - val_loss: 0.0707 - val_accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "# freeze layers \n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# after change always need to COMPILE AGAIN \n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4dcc28b2bafc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_B' is not defined"
     ]
    }
   ],
   "source": [
    "model_B.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Faster Optimizers\n",
    "\n",
    "- Momentum Optimizer (nesterov)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum = 0.9, nesterov=]True)\n",
    "\n",
    "- AdaGrad\n",
    "\n",
    "keras.optimizers.Adagrad(lr=0.001)\n",
    "\n",
    "- RMSProp\n",
    "\n",
    "- Adam and Nadam\n",
    "\n",
    "keras.optimizers.Adam(lr= 0.001, beta_1= 0.9, beta_2 = 0.999)\n",
    "\n",
    ".Nadam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning Rate Scheduling\n",
    "\n",
    "- Power Scheduling\n",
    "\n",
    "- Exponential Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 15s 276us/sample - loss: 0.8450 - accuracy: 0.7559 - val_loss: 1.0001 - val_accuracy: 0.6830\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 14s 252us/sample - loss: 0.7001 - accuracy: 0.7842 - val_loss: 0.6712 - val_accuracy: 0.8162\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 13s 230us/sample - loss: 0.6237 - accuracy: 0.8139 - val_loss: 0.7257 - val_accuracy: 0.7668\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 13s 233us/sample - loss: 0.5778 - accuracy: 0.8272 - val_loss: 0.6870 - val_accuracy: 0.7704\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 12s 221us/sample - loss: 0.5301 - accuracy: 0.8431 - val_loss: 0.5183 - val_accuracy: 0.8474\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 13s 238us/sample - loss: 0.4653 - accuracy: 0.8573 - val_loss: 0.5665 - val_accuracy: 0.8612\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 12s 220us/sample - loss: 0.4255 - accuracy: 0.8683 - val_loss: 0.5246 - val_accuracy: 0.8414\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 12s 219us/sample - loss: 0.3876 - accuracy: 0.8767 - val_loss: 0.5199 - val_accuracy: 0.8696\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 12s 216us/sample - loss: 0.3536 - accuracy: 0.8839 - val_loss: 0.4833 - val_accuracy: 0.8654\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 12s 221us/sample - loss: 0.3282 - accuracy: 0.8908 - val_loss: 0.4463 - val_accuracy: 0.8682\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 13s 240us/sample - loss: 0.3103 - accuracy: 0.8956 - val_loss: 0.4194 - val_accuracy: 0.8848\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 13s 237us/sample - loss: 0.2812 - accuracy: 0.9041 - val_loss: 0.4460 - val_accuracy: 0.8780\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 12s 227us/sample - loss: 0.2642 - accuracy: 0.9094 - val_loss: 0.4356 - val_accuracy: 0.8774\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 13s 233us/sample - loss: 0.2436 - accuracy: 0.9154 - val_loss: 0.4456 - val_accuracy: 0.8796\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 13s 235us/sample - loss: 0.2279 - accuracy: 0.9196 - val_loss: 0.4844 - val_accuracy: 0.8778\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 13s 235us/sample - loss: 0.2123 - accuracy: 0.9258 - val_loss: 0.4720 - val_accuracy: 0.8816\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 13s 243us/sample - loss: 0.1935 - accuracy: 0.9317 - val_loss: 0.4788 - val_accuracy: 0.8832\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 13s 238us/sample - loss: 0.1804 - accuracy: 0.9358 - val_loss: 0.4673 - val_accuracy: 0.8878\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 13s 244us/sample - loss: 0.1703 - accuracy: 0.9398 - val_loss: 0.4851 - val_accuracy: 0.8818\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 13s 243us/sample - loss: 0.1582 - accuracy: 0.9441 - val_loss: 0.4731 - val_accuracy: 0.8896\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 14s 251us/sample - loss: 0.1450 - accuracy: 0.9486 - val_loss: 0.4755 - val_accuracy: 0.8894\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 13s 232us/sample - loss: 0.1358 - accuracy: 0.9527 - val_loss: 0.5085 - val_accuracy: 0.8898\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 12s 223us/sample - loss: 0.1265 - accuracy: 0.9562 - val_loss: 0.5219 - val_accuracy: 0.8926\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 12s 225us/sample - loss: 0.1189 - accuracy: 0.9591 - val_loss: 0.5211 - val_accuracy: 0.8918\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 13s 230us/sample - loss: 0.1092 - accuracy: 0.9629 - val_loss: 0.5764 - val_accuracy: 0.8914\n"
     ]
    }
   ],
   "source": [
    "# Exponential\n",
    "\n",
    "#lr = lr0 * 0.1**(epoch / s)\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "# get the exponential fuction into LearningRateScheduler() of keras.callbacks\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Learning Rate (per batch)\n",
    "\n",
    "### Pieacewise Constant Scheduling \n",
    "\n",
    "- lots of manual fiddling to get good values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.ReduceLROnPlateau at 0x17759c723c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Performance Scheduling\n",
    "\n",
    "keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience= 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 9s 156us/sample - loss: 0.4842 - accuracy: 0.8318 - val_loss: 0.4174 - val_accuracy: 0.8556\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 8s 147us/sample - loss: 0.3787 - accuracy: 0.8648 - val_loss: 0.3772 - val_accuracy: 0.8688\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 8s 151us/sample - loss: 0.3451 - accuracy: 0.8768 - val_loss: 0.3684 - val_accuracy: 0.8700\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.3235 - accuracy: 0.8842 - val_loss: 0.3519 - val_accuracy: 0.8776\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 8s 144us/sample - loss: 0.3067 - accuracy: 0.8910 - val_loss: 0.3438 - val_accuracy: 0.8818\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 8s 148us/sample - loss: 0.2942 - accuracy: 0.8945 - val_loss: 0.3414 - val_accuracy: 0.8814\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2832 - accuracy: 0.8990 - val_loss: 0.3360 - val_accuracy: 0.8848\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 8s 152us/sample - loss: 0.2742 - accuracy: 0.9022 - val_loss: 0.3309 - val_accuracy: 0.8848\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.2664 - accuracy: 0.9041 - val_loss: 0.3279 - val_accuracy: 0.8898\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 8s 153us/sample - loss: 0.2595 - accuracy: 0.9071 - val_loss: 0.3295 - val_accuracy: 0.8866\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 8s 150us/sample - loss: 0.2537 - accuracy: 0.9094 - val_loss: 0.3244 - val_accuracy: 0.8888\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.2486 - accuracy: 0.9109 - val_loss: 0.3234 - val_accuracy: 0.8910\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 8s 153us/sample - loss: 0.2442 - accuracy: 0.9124 - val_loss: 0.3230 - val_accuracy: 0.8896\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.2404 - accuracy: 0.9148 - val_loss: 0.3235 - val_accuracy: 0.8914\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 8s 144us/sample - loss: 0.2370 - accuracy: 0.9164 - val_loss: 0.3201 - val_accuracy: 0.8904\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.2337 - accuracy: 0.9167 - val_loss: 0.3209 - val_accuracy: 0.8910\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 8s 152us/sample - loss: 0.2313 - accuracy: 0.9185 - val_loss: 0.3189 - val_accuracy: 0.8914\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.2284 - accuracy: 0.9187 - val_loss: 0.3212 - val_accuracy: 0.8898\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2265 - accuracy: 0.9199 - val_loss: 0.3198 - val_accuracy: 0.8912\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2246 - accuracy: 0.9213 - val_loss: 0.3183 - val_accuracy: 0.8930\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 9s 157us/sample - loss: 0.2229 - accuracy: 0.9218 - val_loss: 0.3180 - val_accuracy: 0.8906\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2213 - accuracy: 0.9228 - val_loss: 0.3176 - val_accuracy: 0.8904\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2200 - accuracy: 0.9226 - val_loss: 0.3177 - val_accuracy: 0.8922\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 8s 144us/sample - loss: 0.2187 - accuracy: 0.9235 - val_loss: 0.3184 - val_accuracy: 0.8908\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 9s 155us/sample - loss: 0.2178 - accuracy: 0.9237 - val_loss: 0.3175 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "### tf.keras schedulers\n",
    "\n",
    "# special schedulers in tf.keras only\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_steps_per_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0569d1560c59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mboundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_steps_per_epoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     values=[0.01, 0.005, 0.001])\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_steps_per_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "# for piecewise constant scheduling\n",
    "\n",
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1Cycle Scheduling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.4 Avoiding Overfitting through regularization\n",
    "\n",
    "1. l1 and l2 Regularization <br>\n",
    "    - in layers.Dense(...., kernel_init = ..., kernel_regularizer = keras.ergularizers.l2(0.01)))\n",
    "    \n",
    "\n",
    "2. Dropout <br>\n",
    "    - add layers.Dropout(rate=0.2) after .Dense()\n",
    "    - make neurons inactive (outputs zero)\n",
    "    - destructive technique but better results - in daily work life too ? randomly send workers home every morning ?\n",
    "\n",
    "3. MonteCarlo Dropout\n",
    "\n",
    "4. MaxNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise :\n",
    "\n",
    "No. 8 Deep Learning on CIFAR10\n",
    "\n",
    "- build DNN with 20 hidden layers, 100 neurons He_uniform and activation=\"elu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 201s 1us/step\n"
     ]
    }
   ],
   "source": [
    "### setup\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# clear backend cache\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# for reproducability set seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## NO. 8 a) build model \n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3])) # 32 x 32 pixels and 3 for colors\n",
    "\n",
    "for layer in range(20):\n",
    "    model.add(keras.layers.Dense(100, \n",
    "                       activation=\"elu\",\n",
    "                      kernel_initializer= \"he_normal\"))\n",
    "    \n",
    "## No. 8 b)\n",
    "\n",
    "# add output layer to model (since 10 classes softmax function)\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "# get data\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# split train set in valid set ?\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]\n",
    "\n",
    "#  - Compile(opti = Nadam, etc )\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "              optimizer = keras.optimizers.Nadam(lr=5e-5, beta_1 = 0.9, beta_2 = 0.99),\n",
    "              metrics = [\"accuracy\"]\n",
    "             )\n",
    "#  define callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience = 5,)\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\",  save_best_only= True)\n",
    "\n",
    "run_index = 1 # ALWAYS INCREMENT manually !!!!!!!!!!!!!1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 16136."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=20,\n",
    "         validation_data=(X_valid, y_valid),\n",
    "         callbacks = [early_stopping, model_checkpoint, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 53s 1ms/sample - loss: 1.8487 - accuracy: 0.3380 - val_loss: 1.6449 - val_accuracy: 0.4122\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 35s 772us/sample - loss: 1.6679 - accuracy: 0.4053 - val_loss: 1.5977 - val_accuracy: 0.4248\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 36s 798us/sample - loss: 1.5985 - accuracy: 0.4314 - val_loss: 1.5244 - val_accuracy: 0.4512\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 36s 791us/sample - loss: 1.5461 - accuracy: 0.4506 - val_loss: 1.4796 - val_accuracy: 0.4734\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 35s 788us/sample - loss: 1.5099 - accuracy: 0.4643 - val_loss: 1.4376 - val_accuracy: 0.4904\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 36s 791us/sample - loss: 1.4709 - accuracy: 0.4793 - val_loss: 1.4287 - val_accuracy: 0.4870\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 36s 802us/sample - loss: 1.4415 - accuracy: 0.4905 - val_loss: 1.4094 - val_accuracy: 0.4962\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 39s 866us/sample - loss: 1.4138 - accuracy: 0.4973 - val_loss: 1.4158 - val_accuracy: 0.5024\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 40s 882us/sample - loss: 1.3847 - accuracy: 0.5091 - val_loss: 1.3961 - val_accuracy: 0.5020\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 40s 893us/sample - loss: 1.3603 - accuracy: 0.5209 - val_loss: 1.3727 - val_accuracy: 0.5120\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 39s 858us/sample - loss: 1.3395 - accuracy: 0.5260 - val_loss: 1.3650 - val_accuracy: 0.5216\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 37s 819us/sample - loss: 1.3204 - accuracy: 0.5329 - val_loss: 1.3799 - val_accuracy: 0.5174\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 39s 868us/sample - loss: 1.3023 - accuracy: 0.5405 - val_loss: 1.3666 - val_accuracy: 0.5216\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 41s 909us/sample - loss: 1.2809 - accuracy: 0.5445 - val_loss: 1.3580 - val_accuracy: 0.5212\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 40s 878us/sample - loss: 1.2663 - accuracy: 0.5540 - val_loss: 1.4015 - val_accuracy: 0.5084\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 39s 866us/sample - loss: 1.2466 - accuracy: 0.5589 - val_loss: 1.3747 - val_accuracy: 0.5222\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 37s 821us/sample - loss: 1.2295 - accuracy: 0.5668 - val_loss: 1.3459 - val_accuracy: 0.5310\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 40s 884us/sample - loss: 1.2174 - accuracy: 0.5707 - val_loss: 1.3279 - val_accuracy: 0.5392\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 37s 820us/sample - loss: 1.2000 - accuracy: 0.5762 - val_loss: 1.3266 - val_accuracy: 0.5368\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 36s 792us/sample - loss: 1.1897 - accuracy: 0.5802 - val_loss: 1.3506 - val_accuracy: 0.5306\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 35s 784us/sample - loss: 1.1794 - accuracy: 0.5844 - val_loss: 1.3351 - val_accuracy: 0.5320\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 37s 817us/sample - loss: 1.1638 - accuracy: 0.5884 - val_loss: 1.3423 - val_accuracy: 0.5342\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 35s 778us/sample - loss: 1.1495 - accuracy: 0.5947 - val_loss: 1.3361 - val_accuracy: 0.5372\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 36s 793us/sample - loss: 1.1375 - accuracy: 0.6001 - val_loss: 1.3256 - val_accuracy: 0.5344\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 36s 802us/sample - loss: 1.1237 - accuracy: 0.6031 - val_loss: 1.3517 - val_accuracy: 0.5250\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 36s 810us/sample - loss: 1.1140 - accuracy: 0.6056 - val_loss: 1.3445 - val_accuracy: 0.5328\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 36s 803us/sample - loss: 1.0979 - accuracy: 0.6152 - val_loss: 1.3834 - val_accuracy: 0.5260\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 36s 795us/sample - loss: 1.0933 - accuracy: 0.6160 - val_loss: 1.3798 - val_accuracy: 0.5250\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 36s 792us/sample - loss: 1.0766 - accuracy: 0.6174 - val_loss: 1.3429 - val_accuracy: 0.5414\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 37s 815us/sample - loss: 1.0704 - accuracy: 0.6239 - val_loss: 1.3847 - val_accuracy: 0.5262\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 38s 840us/sample - loss: 1.0574 - accuracy: 0.6249 - val_loss: 1.3526 - val_accuracy: 0.5398\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 36s 802us/sample - loss: 1.0483 - accuracy: 0.6306 - val_loss: 1.3633 - val_accuracy: 0.5342\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 37s 828us/sample - loss: 1.0415 - accuracy: 0.6316 - val_loss: 1.3486 - val_accuracy: 0.5450\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 36s 802us/sample - loss: 1.0246 - accuracy: 0.6393 - val_loss: 1.3459 - val_accuracy: 0.5460\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 38s 842us/sample - loss: 1.0240 - accuracy: 0.6399 - val_loss: 1.3857 - val_accuracy: 0.5320\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 38s 847us/sample - loss: 1.0066 - accuracy: 0.6444 - val_loss: 1.3514 - val_accuracy: 0.5388\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 37s 820us/sample - loss: 0.9983 - accuracy: 0.6486 - val_loss: 1.3745 - val_accuracy: 0.5318\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 37s 821us/sample - loss: 0.9899 - accuracy: 0.6509 - val_loss: 1.3783 - val_accuracy: 0.5374\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 40s 878us/sample - loss: 0.9853 - accuracy: 0.6531 - val_loss: 1.3858 - val_accuracy: 0.5364\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 37s 826us/sample - loss: 0.9727 - accuracy: 0.6549 - val_loss: 1.4061 - val_accuracy: 0.5262\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 37s 819us/sample - loss: 0.9575 - accuracy: 0.6609 - val_loss: 1.3971 - val_accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 36s 796us/sample - loss: 0.9598 - accuracy: 0.6626 - val_loss: 1.3991 - val_accuracy: 0.5318\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 36s 811us/sample - loss: 0.9452 - accuracy: 0.6654 - val_loss: 1.3555 - val_accuracy: 0.5462\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 12407s 276ms/sample - loss: 0.9346 - accuracy: 0.6674 - val_loss: 1.3696 - val_accuracy: 0.5418\n",
      "10000/10000 [==============================] - 3s 297us/sample - loss: 1.3459 - accuracy: 0.5268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3459499521255494, 0.5268]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exercise 8 c)\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# 1) build the same Model with BN \n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3])) # 32 x 32 pixels and 3 for colors\n",
    "\n",
    "# first BN (for regularization)\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# for each hidden layer a BN (since after Dense Layer, Activation muss be seperated)\n",
    "for layer in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                      kernel_initializer= \"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "    \n",
    "# last output layer same \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# 2) compile, callbacks, and training same (except different name for logs)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "# 3) load the best model and evaluate\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 8 d)\n",
    "\n",
    "# lecun initialization, no BN, \"selu\" and standardize data = (x - mean) / std\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1) model\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Flatten(input_shape= [32, 32, 3]))\n",
    "\n",
    "for layer in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initialization = 'lecun_normal',\n",
    "                                activation = 'selu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "optimizer = keras.optimizer.Nadam(lr = 7e-4)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = optimizer,\n",
    "             metrics = ['accuracy'])\n",
    "# callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "# standardize values\n",
    "\n",
    "x_mean = X_train.mean(axis=0)\n",
    "x_std = X_train.std(axis=0)\n",
    "\n",
    "X_train_scaled = (X_train - x_mean )/ x_std\n",
    "X_valid_scaled = (X_valid - x_mean) / x_std\n",
    "X_test_scaled = (X_test - x_mean ) / x_std\n",
    "\n",
    "\n",
    "# train model \n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "         validation_data = (X_valid, y_valid),\n",
    "         callbacks = callbacks)\n",
    "\n",
    "# get best model and evaluate\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8 e.)\n",
    "\n",
    "# use AlphaDropout\n",
    "\n",
    "# just add .... in for loop\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.2)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
